apiVersion: v1
kind: Pod
metadata:
  name: "{{ .AppName }}--ingest-docs"
  labels:
    ai-services.io/application: "{{ .AppName }}"
    ai-services.io/template: "{{ .AppTemplateName }}"
    ai-services.io/version: "{{ .Version }}"
  annotations:
    ai-services.io/start: "off"
spec:
  containers:
    - name: ingest-docs
      image: "{{ .Values.backend.image }}"
      command:
        - "/var/venv/bin/python"
        - "-m"
        - "digitize.cli"
        - "ingest"
      resources:
        requests:
          memory: "50Gi"
        limits:
          memory: "50Gi"
      env:
        - name: EMB_ENDPOINT
          value: "http://{{ .AppName  }}--vllm-server:8001"
        - name: EMB_MODEL
          value: "ibm-granite/granite-embedding-278m-multilingual"
        - name: EMB_MAX_TOKENS
          value: "512"
        - name: LLM_ENDPOINT
          value: "http://{{ .AppName  }}--vllm-server:8000"
        - name: LLM_MODEL
          value: "ibm-granite/granite-3.3-8b-instruct"
        - name: OPENSEARCH_HOST
          value: "{{ .AppName  }}--opensearch"
        - name: OPENSEARCH_PORT
          value: "9200"
        - name: OPENSEARCH_DB_PREFIX
          value: "RAG_DB"
        - name: OPENSEARCH_INDEX_NAME
          value: "RAG_INDEX"
        - name: OPENSEARCH_USERNAME
          value: "{{ .Values.opensearch.username }}"
        - name: OPENSEARCH_PASSWORD
          value: "{{ .Values.opensearch.password }}"
        - name: LOG_LEVEL
          value: "{{ .Values.ingest.log_level}}"
      volumeMounts:
        - mountPath: /var/docs:z
          name: docs
          readOnly: true
        - mountPath: /var/cache:z
          name: cache
  restartPolicy: Never
  volumes:
    - name: docs
      hostPath:
        path: "/var/lib/ai-services/applications/{{ .AppName }}/docs"
        type: DirectoryOrCreate
    - name: cache
      hostPath:
        path: "/var/lib/ai-services/applications/{{ .AppName }}/cache"
        type: DirectoryOrCreate
